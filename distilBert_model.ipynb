{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufrCaaIF0aRM",
        "outputId": "0ad50683-4e34-4f9c-ba7e-d26ea50f7d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTn2TQeXBs5M",
        "outputId": "0c205a4c-9e07-4045-fba6-f292aef19038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcjCpE2FB1W_",
        "outputId": "72c5846c-4425-4be1-e252-a0ace85b8a11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.12/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch datasets scikit-learn pandas numpy seaborn matplotlib lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXnBTtl1VH6R",
        "outputId": "bcda8ed6-54ee-478c-bd77-442d511a7c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXuiz0WlB3x_",
        "outputId": "fd9c72ee-f583-4824-d93e-1890c5ae8a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# 0. Import & Config\n",
        "# ======================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "DATA_FAKE_PATH = \"/content/drive/MyDrive/Data-Raws/fake_news.csv\"\n",
        "DATA_TRUE_PATH = \"/content/drive/MyDrive/Data-Raws/true_news.csv\"\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "MAX_LENGTH = 128\n",
        "RANDOM_SEED = 42\n",
        "N_SPLITS = 3  # k-fold\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqx2e8tuB-NF",
        "outputId": "5667f68c-9ec2-4534-d94d-952658da67ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           full_text  label\n",
            "0  Donald Trump Sends Out Embarrassing New Year’s...      1\n",
            "1  Drunk Bragging Trump Staffer Started Russian C...      1\n",
            "2  Sheriff David Clarke Becomes An Internet Joke ...      1\n",
            "3  Trump Is So Obsessed He Even Has Obama’s Name ...      1\n",
            "4  Pope Francis Just Called Out Donald Trump Duri...      1\n",
            "Total samples: 44889\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# 1. Load & Cleaning\n",
        "# ======================\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
        "    text = re.sub(r\"<.*?>\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "fake_df = pd.read_csv(DATA_FAKE_PATH)\n",
        "true_df = pd.read_csv(DATA_TRUE_PATH)\n",
        "\n",
        "fake_df[\"full_text\"] = (fake_df[\"title\"].fillna(\"\") + \" \" + fake_df[\"text\"].fillna(\"\")).apply(clean_text)\n",
        "true_df[\"full_text\"] = (true_df[\"title\"].fillna(\"\") + \" \" + true_df[\"text\"].fillna(\"\")).apply(clean_text)\n",
        "\n",
        "fake_df[\"label\"] = 1\n",
        "true_df[\"label\"] = 0\n",
        "\n",
        "df = pd.concat(\n",
        "    [fake_df[[\"full_text\", \"label\"]], true_df[[\"full_text\", \"label\"]]],\n",
        "    axis=0\n",
        ").reset_index(drop=True)\n",
        "\n",
        "df = df[df[\"full_text\"].str.len() > 0].reset_index(drop=True)\n",
        "\n",
        "print(df.head())\n",
        "print(\"Total samples:\", len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "mXjZbI12B-KV",
        "outputId": "cf6895f6-dad0-4a5b-95a0-689000bbe403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label distribution:\n",
            "label\n",
            "1    23472\n",
            "0    21417\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Label ratio:\n",
            "label\n",
            "1    0.52289\n",
            "0    0.47711\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Text length statistics:\n",
            "count    44889.000000\n",
            "mean       417.691149\n",
            "std        351.431566\n",
            "min          4.000000\n",
            "25%        216.000000\n",
            "50%        375.000000\n",
            "75%        526.000000\n",
            "max       8148.000000\n",
            "Name: text_len, dtype: float64\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ======================\n",
        "# 2. EDA\n",
        "# ======================\n",
        "\n",
        "print(\"Label distribution:\")\n",
        "print(df[\"label\"].value_counts())\n",
        "print(\"\\nLabel ratio:\")\n",
        "print(df[\"label\"].value_counts(normalize=True))\n",
        "\n",
        "df[\"text_len\"] = df[\"full_text\"].str.split().apply(len)\n",
        "print(\"\\nText length statistics:\")\n",
        "print(df[\"text_len\"].describe())\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(df[\"text_len\"], bins=50)\n",
        "plt.title(\"Distribution of text lengths\")\n",
        "plt.xlabel(\"Number of tokens\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Hiển thị trực tiếp trong notebook\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C1npmtvB-IW",
        "outputId": "3220b709-c4f8-43a8-de1e-4a6786dce304"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# 3. Tokenizer & Dataset\n",
        "# ======================\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "class FakeNewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = list(texts)\n",
        "        self.labels = list(labels)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        enc = tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        item = {k: v.squeeze(0) for k,v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(label)\n",
        "        return item\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Re6MmsajB-Gb"
      },
      "outputs": [],
      "source": [
        "# ======================\n",
        "# 4. Metrics function\n",
        "# ======================\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "i-57upTPBbTb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gu5bmmpRB97g",
        "outputId": "e43dfd2c-73ad-456c-9422-0bdfcd2dd9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1/3 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1871' max='1871' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1871/1871 04:52, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.208300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.008100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.009300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.023600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.009100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.007400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.018600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.019200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.009600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.009100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.008200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.9993985163403061, 'precision': 0.9988510149368058, 'recall': 1.0, 'f1': 0.9994251772370186}\n",
            "\n",
            "--- Fold 2/3 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1871' max='1871' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1871/1871 04:36, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.261500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.012200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.007300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.011100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.011400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.009300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.011000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.011100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.015700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.015800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.9997326739290249, 'precision': 0.9996166624073601, 'recall': 0.9998721881390593, 'f1': 0.999744408945687}\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1871' max='1871' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1871/1871 04:16, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.240600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.013300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.032200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.010500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.019000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.008400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.008200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.9991311902693311, 'precision': 0.9988504278962831, 'recall': 0.9994887525562373, 'f1': 0.9991694882770076}\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# 5. K-FOLD CROSS VALIDATION (TỐI ƯU)\n",
        "# ======================\n",
        "\n",
        "X = df[\"full_text\"].values\n",
        "y = df[\"label\"].values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "fold_metrics = []\n",
        "\n",
        "fold_id = 1\n",
        "for train_idx, val_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n--- Fold {fold_id}/{N_SPLITS} ---\")\n",
        "\n",
        "    train_dataset = FakeNewsDataset(X[train_idx], y[train_idx], tokenizer, MAX_LENGTH)\n",
        "    val_dataset   = FakeNewsDataset(X[val_idx], y[val_idx], tokenizer, MAX_LENGTH)\n",
        "\n",
        "    fold_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME, num_labels=2\n",
        "    ).to(device)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./distilbert_fold_{fold_id}\",\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=32,\n",
        "        fp16=True,\n",
        "        learning_rate=3e-5,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        logging_dir=f\"./logs_fold_{fold_id}\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=fold_model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    eval_results = trainer.predict(val_dataset)\n",
        "    metrics = compute_metrics((eval_results.predictions, eval_results.label_ids))\n",
        "    print(metrics)\n",
        "\n",
        "    fold_metrics.append(metrics)\n",
        "    fold_id += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUv3nWcdCGsf",
        "outputId": "8ffd26f1-2a5e-40a3-b77b-469bed11a6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Cross-Validation Summary ===\n",
            "accuracy: 0.9994 ± 0.0002\n",
            "precision: 0.9991 ± 0.0004\n",
            "recall: 0.9998 ± 0.0002\n",
            "f1: 0.9994 ± 0.0002\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# 6. K-FOLD SUMMARY\n",
        "# ======================\n",
        "\n",
        "print(\"\\n=== Cross-Validation Summary ===\")\n",
        "for m in fold_metrics[0].keys():\n",
        "    scores = [f[m] for f in fold_metrics]\n",
        "    print(f\"{m}: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "81UFzj5ZFMYL",
        "outputId": "e3593efd-79ce-4795-89e4-cad79087340b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.57.1'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "9fsl6sBSCGpC",
        "outputId": "fa7b7b8c-5194-4bf8-ad70-7b0687904f34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7575' max='7575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7575/7575 15:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.002882</td>\n",
              "      <td>0.999554</td>\n",
              "      <td>0.999149</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.010500</td>\n",
              "      <td>0.007354</td>\n",
              "      <td>0.998441</td>\n",
              "      <td>0.999573</td>\n",
              "      <td>0.997444</td>\n",
              "      <td>0.998507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002205</td>\n",
              "      <td>0.999777</td>\n",
              "      <td>0.999574</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7575, training_loss=0.0042630882969390445, metrics={'train_runtime': 916.7652, 'train_samples_per_second': 132.204, 'train_steps_per_second': 8.263, 'total_flos': 4013762179276800.0, 'train_loss': 0.0042630882969390445, 'epoch': 3.0})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ======================\n",
        "# 7. TRAIN FINAL MODEL (TỐI ƯU)\n",
        "# ======================\n",
        "\n",
        "X_train_full, X_test_holdout, y_train_full, y_test_holdout = train_test_split(\n",
        "    X, y, test_size=0.1, stratify=y, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "train_full_dataset = FakeNewsDataset(X_train_full, y_train_full, tokenizer, MAX_LENGTH)\n",
        "test_holdout_dataset = FakeNewsDataset(X_test_holdout, y_test_holdout, tokenizer, MAX_LENGTH)\n",
        "\n",
        "final_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=2\n",
        ").to(device)\n",
        "\n",
        "final_args = TrainingArguments(\n",
        "    output_dir=\"./distilbert_final\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "\n",
        "    fp16=True,\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "\n",
        "    logging_steps=50,\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "final_trainer = Trainer(\n",
        "    model=final_model,\n",
        "    args=final_args,\n",
        "    train_dataset=train_full_dataset,\n",
        "    eval_dataset=test_holdout_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "final_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "XOAibvc5COmF",
        "outputId": "c9879fdd-7a0c-4c9c-ac9b-f3816559c339"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Hold-Out Performance:\n",
            "Accuracy : 0.9998\n",
            "Precision: 0.9996\n",
            "Recall   : 1.0000\n",
            "F1-score : 0.9998\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2142\n",
            "           1       1.00      1.00      1.00      2347\n",
            "\n",
            "    accuracy                           1.00      4489\n",
            "   macro avg       1.00      1.00      1.00      4489\n",
            "weighted avg       1.00      1.00      1.00      4489\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved!\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# 8. EVALUATION OF FINAL MODEL\n",
        "# ======================\n",
        "\n",
        "test_results = final_trainer.predict(test_holdout_dataset)\n",
        "logits = test_results.predictions\n",
        "labels = test_results.label_ids\n",
        "preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "acc = accuracy_score(labels, preds)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "\n",
        "print(\"\\nFinal Hold-Out Performance:\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1-score : {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(labels, preds))\n",
        "\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"real\",\"fake\"], yticklabels=[\"real\",\"fake\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "final_model.save_pretrained(\"./distilbert_final\")\n",
        "tokenizer.save_pretrained(\"./distilbert_final\")\n",
        "\n",
        "print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LQK7b1M4CRkX"
      },
      "outputs": [],
      "source": [
        "# ======================\n",
        "# 9. INFERENCE + LIME EXPLAINABILITY\n",
        "# ======================\n",
        "\n",
        "class_names = [\"real\", \"fake\"]\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "\n",
        "def predict_single(text):\n",
        "    final_model.eval()\n",
        "    with torch.no_grad():\n",
        "        enc = tokenizer(text, truncation=True, padding=\"max_length\",\n",
        "                        max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
        "        enc = {k: v.to(device) for k,v in enc.items()}\n",
        "        outputs = final_model(**enc)\n",
        "        probs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()[0]\n",
        "        pred = int(np.argmax(probs))\n",
        "    return {\"label\": class_names[pred], \"real_prob\": float(probs[0]), \"fake_prob\": float(probs[1])}\n",
        "\n",
        "def lime_predict_proba(texts):\n",
        "    final_model.eval()\n",
        "    probs_list = []\n",
        "    for t in texts:\n",
        "        with torch.no_grad():\n",
        "            enc = tokenizer(t, truncation=True, padding=\"max_length\",\n",
        "                            max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
        "            enc = {k: v.to(device) for k,v in enc.items()}\n",
        "            out = final_model(**enc)\n",
        "            probs_list.append(torch.softmax(out.logits, dim=-1).cpu().numpy()[0])\n",
        "    return np.array(probs_list)\n",
        "\n",
        "def explain_prediction(text, num_features=10):\n",
        "    pred = predict_single(text)\n",
        "    print(\"Prediction:\", pred)\n",
        "\n",
        "    exp = explainer.explain_instance(\n",
        "        text_instance=text,\n",
        "        classifier_fn=lime_predict_proba,\n",
        "        num_features=num_features,\n",
        "        labels=[0,1]\n",
        "    )\n",
        "\n",
        "    print(\"\\nWords pushing → FAKE:\")\n",
        "    for w, weight in exp.as_list(label=1):\n",
        "        print(f\"{w:20s} {weight:.4f}\")\n",
        "\n",
        "    print(\"\\nWords pushing → REAL:\")\n",
        "    for w, weight in exp.as_list(label=0):\n",
        "        print(f\"{w:20s} {weight:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J38lTuYfCVKu",
        "outputId": "69fa2b9d-7748-4be8-f576-ebaaa023f00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'label': 'fake', 'real_prob': 7.889262633398175e-06, 'fake_prob': 0.9999921321868896}\n",
            "Prediction: {'label': 'fake', 'real_prob': 7.889262633398175e-06, 'fake_prob': 0.9999921321868896}\n",
            "\n",
            "Words pushing → FAKE:\n",
            "t                    0.0008\n",
            "Trashes              0.0008\n",
            "they                 0.0008\n",
            "Trump                0.0008\n",
            "has                  0.0008\n",
            "Kooky                0.0008\n",
            "as                   0.0007\n",
            "about                0.0007\n",
            "know                 0.0007\n",
            "17                   0.0003\n",
            "\n",
            "Words pushing → REAL:\n",
            "t                    -0.0008\n",
            "Trashes              -0.0008\n",
            "they                 -0.0008\n",
            "Trump                -0.0008\n",
            "has                  -0.0008\n",
            "Kooky                -0.0008\n",
            "as                   -0.0007\n",
            "about                -0.0007\n",
            "know                 -0.0007\n",
            "17                   -0.0003\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# 10. Example test\n",
        "# ======================\n",
        "\n",
        "sample = df[\"full_text\"].iloc[13]\n",
        "print(predict_single(sample))\n",
        "explain_prediction(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbpsLU3de-1X",
        "outputId": "03e9dad9-dc41-4c23-eff6-608b5c722319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== SAMPLE INDEX: 41905 ====\n",
            "TRUE LABEL: real\n",
            "\n",
            "TEXT:\n",
            " Spanish court grants U.S. extradition for Russian hacking suspect MADRID (Reuters) - Spain s High Court said on Tuesday it had granted a U.S. request to extradite Russian citizen Peter Levashov, who is accused of U.S. hacking offences including operating a network of infected computers used by cyber criminals. Levashov, 36, was arrested while on holiday in Barcelona in April. U.S. prosecutors have accused him of running the Kelihos botnet, a network of more than 100,000 infected devices used by cyber criminals to distribute viruses, ransomware, phishing emails and other spam attacks. U.S. prosecutors are seeking a 52-year jail sentence against Levashov, who denies the charges against him. The Spanish court said Levashov had three days to lodge an appeal against the extradition decision. Levashov, who is fighting extradition, told the Madrid court last week that he had worked for President Vladimir Putin s United Russia party for the last 10 years, Russia s RIA news agency reported. He told the court that investigators in the United States would torture him for information about his political work if he was sent there to face the charges. If I go to the U.S., I will die in a year. They want to get information of a military nature and about the United Russia party, RIA quoted him as saying. I will be tortured, within a year I will be killed, or I will kill myself. The Spanish court ruling said that Levashov s lawyers had also alleged a political motivation behind the U.S. request for his extradition and that the real reason behind it may be that he was a programmer who might have hacked the U.S. elections . U.S. intelligence agencies have concluded that the Kremlin orchestrated a wide-ranging influence operation that included email hacking and online propaganda to discredit Democratic presidential candidate Hillary Clinton and help Donald Trump, a Republican, win the White House last November. The Kremlin denies the allegations. The Spanish court dismissed all the arguments put forward by Levashov and his lawyers against extradition. Nothing has been proven with respect to the allegations about political motivation and neither ... has the potential infringement of the accused s right to life or of his physical integrity, the court ruling sad. In an eight-count indictment handed down by a federal grand jury in Connecticut in April, Levashov was charged with causing intentional damage to a protected computer and wire fraud. Russia has lodged its own request for Levashov s extradition from Spain, RIA reported.\n",
            "\n",
            "MODEL PREDICTION: {'label': 'real', 'real_prob': 0.9999990463256836, 'fake_prob': 9.422445828022319e-07}\n",
            "Prediction: {'label': 'real', 'real_prob': 0.9999990463256836, 'fake_prob': 9.422445828022319e-07}\n",
            "\n",
            "Words pushing → FAKE:\n",
            "criminals            -0.0007\n",
            "said                 0.0001\n",
            "programmer           0.0001\n",
            "April                0.0001\n",
            "while                0.0001\n",
            "on                   0.0001\n",
            "s                    0.0001\n",
            "who                  0.0001\n",
            "including            0.0001\n",
            "allegations          0.0001\n",
            "\n",
            "Words pushing → REAL:\n",
            "criminals            0.0007\n",
            "said                 -0.0001\n",
            "programmer           -0.0001\n",
            "April                -0.0001\n",
            "while                -0.0001\n",
            "on                   -0.0001\n",
            "s                    -0.0001\n",
            "who                  -0.0001\n",
            "including            -0.0001\n",
            "allegations          -0.0001\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# ======================\n",
        "# 1. Lấy mẫu ngẫu nhiên\n",
        "# ======================\n",
        "idx = random.randint(0, len(df) - 1)\n",
        "sample_text = df[\"full_text\"].iloc[idx]\n",
        "true_label = df[\"label\"].iloc[idx]\n",
        "\n",
        "print(f\"==== SAMPLE INDEX: {idx} ====\")\n",
        "print(\"TRUE LABEL:\", \"real\" if true_label == 0 else \"fake\")\n",
        "print(\"\\nTEXT:\\n\", sample_text)\n",
        "\n",
        "# ======================\n",
        "# 2. Mô hình dự đoán\n",
        "# ======================\n",
        "pred = predict_single(sample_text)\n",
        "print(\"\\nMODEL PREDICTION:\", pred)\n",
        "\n",
        "# ======================\n",
        "# 3. Giải thích bằng LIME\n",
        "# ======================\n",
        "explain_prediction(sample_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
